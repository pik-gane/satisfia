run withthe following:

sorry, i only saw this now. i guess we should do several simulations:
one in which the human is using the policy formed from V_m for a particular goal that the robot had in its set of possible goals
one in which the human is using a newly learned best response against pi_r given that same goal
one in which h is playing a newly learned best response against pi_r given some other goal the robot did not consider
one in which h is acting totally at random
